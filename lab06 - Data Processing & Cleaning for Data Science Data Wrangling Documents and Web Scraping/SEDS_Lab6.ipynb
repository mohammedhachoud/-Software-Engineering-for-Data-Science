{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG src=\"figures/logo-esi-sba.png\" WIDTH=300 height=\"100\" ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# Practical Trainining Series on Software Engineering For Data Science  \n",
    "*By Dr. Belkacem KHALDI (b.khaldi@esi-sba.dz)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Notebook 6: Data Processing & Cleaning for Data Science: Data Wrangling Documents and Web Scraping\n",
    "\n",
    "The purpose of this [Jupyter Notebook] is to getting you introduced to the Data Processing & Cleaning for Data\n",
    "Science: Data Wrangling Documents and Web Scraping. It provides a set of practical Training challenges that allow grasping the different concepts presented in  lecture 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parsing and Processing Text Documents\n",
    "\n",
    "### Challenge 1: \n",
    "Given the text shown in the code below, you are asked to do the basic parsing and processing text operations checklist seen in the lecture (Slides 4-9) to provide a basic text analysis report.\n",
    "\n",
    "``` python\n",
    "import string\n",
    "\n",
    "text = \"\"\"\n",
    "Data science incorporates tools from multiple disciplines to gather a data set, process, and derive insights from the data set, extract meaningful data from the set, and interpret it for decision-making purposes. \n",
    "The disciplinary areas that make up the data science field include mining, statistics, machine learning, analytics, and programming.\n",
    "\n",
    "Data mining applies algorithms to the complex data set to reveal patterns that are then used to extract useful and relevant data from the set. \n",
    "Statistical measures or predictive analytics use this extracted data to gauge events that are likely to happen in the future based on what the data shows happened in the past.\n",
    "\n",
    "Machine learning is an artificial intelligence tool that processes mass quantities of data that a human would be unable to process in a lifetime. Machine learning perfects the decision model presented under predictive analytics by matching the likelihood of an event happening to what actually happened at a predicted time.\n",
    "Using analytics, the data analyst collects and processes the structured data from the machine learning stage using algorithms. \n",
    "The analyst interprets, converts, and summarizes the data into a cohesive language that the decision-making team can understand.\n",
    "Data science is applied to practically all contexts and, as the data scientist's role evolves, the field will expand to encompass data architecture, data engineering, and data administration.\n",
    "\"\"\"\n",
    "```\n",
    "\n",
    "`Hint:`\n",
    "These are some of the basic text analysis operations\n",
    "\n",
    "* Reading & Extracting Texts\n",
    "*  Basic Text Cleaning:\n",
    "    * Removing unnecessary punctuation, tags\n",
    "    * Tokenization\n",
    "    * Removing stop words\n",
    "* Basic words Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge 2:\n",
    "You've just started a new data science position at the Cybersecurity Unit of the U.S. DEPARTMENT OF COMMERCE. The department wants to build, test, and evaluate new machine learning model using thier 2020 annual report document availabe in the local data folder:`2020_Cybersecurity_and_Privacy_Annual_Re.docx`. \n",
    "\n",
    "You are asked to provide a visual report summarizing the most common frequency keywords used in their report. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web Scraping: Parsing and processing Web Pages\n",
    "### Challenge 3:\n",
    "We want to analyse text collected from https://en.wikipedia.org/wiki/Data_science  wikipedia page. We are only interested on the text content of links html anchor (`a`).  \n",
    "\n",
    "1. Do the cheklist basic text analyses to provid a visyal summarry of all href text links available on the page.\n",
    "\n",
    "`Hint:`\n",
    "1. Follow and adjust the procedures in Lecture 6 - Slides: 14-16 - to collect the required text. In case, you have not figured out how to collect the required information, here is below a code that help you:\n",
    "\n",
    "\n",
    "``` python\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import lxml\n",
    "\n",
    "url = 'https://en.wikipedia.org/wiki/Data_science'\n",
    "page = urlopen(url).read().decode('utf-8')\n",
    "\n",
    "soup = bs(page)\n",
    "\n",
    "links = soup.find_all('a')\n",
    "all_link_text = []\n",
    "\n",
    "all_link_text.extend([a.text for a in links])\n",
    "\n",
    "text = ' '.join(all_link_text)\n",
    "text\n",
    "``` \n",
    "\n",
    "2. Follow the checklist text analysis to clean and visualize the most common words used in the collected text.\n",
    "\n",
    "### Challenge 4:\n",
    "We want to analyse text related to data science topic collected from different web pages: https://www.heavy.ai/learn/data-science,  https://en.wikipedia.org/wiki/Data_science, https://www.ibm.com/cloud/learn/data-science-introduction, and https://deepai.org/machine-learning-glossary-and-terms/data-science alongside with the text string object of challenge 01.\n",
    "\n",
    "Note that we are only interested on the text content of  html anchor (`p`) from the webpages.  \n",
    "\n",
    "1. Do the required procedures to collect all  `p` text available on all of the aformentioned web pages.\n",
    "2. Append the collected text with the text string object of challenge 01\n",
    "3. Do the cheklist basic text analyses to provid a visyal summarry of the most frequently used keywords on the resulted text.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Your Solution"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
